# Overview of Statistical Analysis

### Statistics Overview

- **Definition**: Branch of mathematics dealing with collection, analysis, interpretation, and presentation of numerical/quantitative data.
- **Applications**: Daily life (e.g., average income, average age, highest-paid professions) and decision-making across industries (e.g., vaccine production safety, reducing customer churn).

### Statistical Analysis

- **Definition**: Application of statistical methods to a data sample to understand what it represents.
- **Components**:
    - **Collection**: Gathering data samples.
    - **Scrutiny**: Examining every data sample.
    - **Sample**: Representative selection drawn from a population.
    - **Population**: Discrete group of people/things identified by at least one common characteristic for data collection and analysis.

### Types of Statistical Methods

1. **Descriptive Statistics**
    - **Purpose**: Summarize information about a sample without making conclusions about the population.
    - **Presentation**: Summary charts, tables, and graphs for easier understanding and visualization.
    - **Common Measures**:
        - **Central Tendency**:
            - **Mean**: Mathematical average.
            - **Median**: Middle value in an ordered dataset.
            - **Mode**: Most frequently occurring value.
        - **Dispersion**: is the measure of variability in a dataset.
            - **Variance**: How far data points fall from the center.
                - Lower variability > Consistent values in a dataset
                - Higher variability > Dissimilar values with likelihood of extreme values
            - **Standard Deviation**: Tells how tightly data is clustered around the mean.
            - **Range**: Distance between smallest and largest values.
        - **Skewness**: Measure of whether the distribution of values is symmetrical around a central value or skewed left or right.
            - Skewed data can affect which types of analyses are valid to perform.
2. **Inferential Statistics**
    - **Purpose**: Make inferences about the larger population from a sample. Helps draw generalizations that apply the results of the sample to the population as a whole
    - **Common Methodologies**:
        - **Hypothesis Testing**: Determine the effectiveness of an intervention (e.g., vaccine efficacy).
        - **Confidence Intervals**: Create a range of values where the actual population value likely falls.
        - **Regression Analysis**: Determine if relationships in sample data exist in the population.

### Software for Statistical Data Analysis

- **Examples**:
    - Statistical Analysis System (SAS)
    - Statistical Package for the Social Sciences (SPSS)
    - Stat Soft

### Statistics in Data Mining

- **Core Role**:
    - Provide measures and methodologies for data mining.
    - Identify patterns to differentiate between random noise and significant findings.
- **Relation to Data Analysis**: Both help in better decision-making through pattern recognition and data interpretation.

# What is Data Mining?

### Data Mining Overview

- **Definition**: Process of extracting knowledge from data; core of data analysis.
- **Field**: Interdisciplinary, involving pattern recognition technologies, statistical analysis, and mathematical techniques.
- **Goal**: Identify correlations, find patterns and variations, understand trends, and predict probabilities.

### Patterns and Trends

- **Pattern Recognition**: Discovery of regularities or commonalities in data.
    - **Example**: Analyzing login data to find user habits (e.g., peak login times, user roles spending maximum hours, frequently used modules).
- **Trends**: General tendency of data to change over time.
    - **Example**: Global warming; despite short-term variations, the overall temperature increases over time.

### Applications of Data Mining

- **Customer Profiling**: Offering targeted campaigns based on customer behaviors, needs, and income.
- **Fraud Detection**: Financial institutions tracking unusual behaviors in transactions.
- **Health Predictions**: Using statistical models to predict patients' likelihood of specific health conditions.
- **Educational Performance**: Predicting student achievement levels for targeted support.
- **Crime Prevention**: Deploying police force based on crime likelihood.
- **Supply Chain Management**: Aligning supply and logistics with demand forecasts.

### Techniques in Data Mining

- **Classification**: Classifies attributes into categories (e.g., low, medium, high spenders based on income).
- **Clustering**: Groups data into clusters for group-based treatment (e.g., customers based on geographic regions).
- **Anomaly Detection**: Finds abnormal or unexpected patterns (e.g., credit card usage spikes).
- **Association Rule Mining**: Establishes relationships between data events (e.g., laptop purchases with cooling pads).
- **Sequential Patterns**: Traces series of events in sequence (e.g., customer shopping trail).
- **Affinity Grouping**: Discovers co-occurrence relationships (e.g., recommending products based on purchase history).
- **Decision Trees**: Builds classification models in tree structure with multiple branches for probable occurrences.
- **Regression**: Identifies relationships between variables, whether causal or correlational (e.g., predicting house value based on location and area).

### Conclusion

- **Purpose**: Data mining helps differentiate noise from real information, focusing businesses on relevant data.

---

### Veri Madenciliği Genel Bakış

- **Tanım**: Veriden bilgi çıkarma süreci; veri analizinin kalbidir.
- **Alan**: Desen tanıma teknolojileri, istatistiksel analiz ve matematiksel teknikleri içeren disiplinler arası.
- **Amaç**: Korelasyonları belirlemek, desen ve varyasyonları bulmak, eğilimleri anlamak ve olasılıkları tahmin etmek.

### Desenler ve Eğilimler

- **Desen Tanıma**: Verideki düzenlilik veya benzerliklerin keşfi.
    - **Örnek**: Kullanıcı alışkanlıklarını bulmak için giriş verilerini analiz etme (örneğin, en yoğun giriş zamanları, maksimum saat harcayan kullanıcı rolleri, sık kullanılan modüller).
- **Eğilimler**: Verinin zaman içinde genel değişim eğilimi.
    - **Örnek**: Küresel ısınma; kısa vadeli değişikliklere rağmen, genel sıcaklık zamanla artar.

### Veri Madenciliğinin Uygulamaları

- **Müşteri Profili Çıkartma**: Müşteri davranışlarına, ihtiyaçlarına ve gelirine dayalı hedefli kampanyalar sunma.
- **Dolandırıcılık Tespiti**: Finansal kurumların alışılmadık davranışları izleme.
- **Sağlık Tahminleri**: Hastaların belirli sağlık koşullarına sahip olma olasılığını tahmin etmek için istatistiksel modeller kullanma.
- **Eğitim Performansı**: Hedefli destek için öğrenci başarı seviyelerini tahmin etme.
- **Suç Önleme**: Suç olasılığına dayalı polis gücü yerleştirme.
- **Tedarik Zinciri Yönetimi**: Talep tahminleriyle tedarik ve lojistiği hizalama.

### Veri Madenciliği Teknikleri

- **Sınıflandırma**: Nitelikleri kategorilere ayırır (örneğin, gelire dayalı olarak düşük, orta, yüksek harcama yapanlar).
- **Kümeleme**: Veriyi gruplara ayırır, böylece gruplar olarak ele alınabilir (örneğin, coğrafi bölgelere dayalı müşteriler).
- **Anomali Tespiti**: Anormal veya beklenmedik desenleri bulur (örneğin, kredi kartı kullanımındaki ani artışlar).
- **Birliktelik Kural Madenciliği**: Veri olayları arasında ilişkiler kurar (örneğin, dizüstü bilgisayar alımı ile soğutma pedi alımı).
- **Sıralı Desenler**: Bir dizi olayın sırasını izler (örneğin, müşteri alışveriş yolu).
- **Benzerlik Grubu**: Ortak ilişkileri keşfeder (örneğin, alışveriş geçmişine dayalı ürün önerileri).
- **Karar Ağaçları**: Birden çok dala sahip ağaç yapısında sınıflandırma modelleri oluşturur.
- **Regresyon**: Değişkenler arasındaki ilişkileri belirler, nedensel veya korelasyonel olabilir (örneğin, konum ve alana dayalı ev değeri tahmini).

### Sonuç

- **Amaç**: Veri madenciliği, gürültüyü gerçek bilgiden ayırmaya yardımcı olur ve işletmelerin sadece ilgili verilere odaklanmasını sağlar.

# Tools for Data Mining

### Common Data Mining Tools

- **Spreadsheets**:
    - Examples: Microsoft Excel, Google Sheets.
    - Uses: Basic data mining tasks, hosting exported data, easy comparison, pivot tables.
    - Add-ins: Data Mining Client for Excel, XLMiner, KnowledgeMiner, Text Analysis, Text Mining, Google Analytics.

### R-Language

- **Popularity**: Widely used for statistical modeling and computations.
- **Libraries**: Hundreds available for regression, classification, clustering, association rule mining, text mining, outlier detection, social network analysis.
- **Packages**:
    - tm: Framework for text mining.
    - twitteR: Framework for mining tweets.
- **IDE**: R Studio, open-source environment for R.

### Python

- **Libraries**:
    - Pandas: Data structures and analysis, basic numerical computations, statistical analysis, data visualization.
    - NumPy: Mathematical computing, data preparation, built-in functions for data mining.
- **Tools**: Jupyter Notebooks for data mining and statistical analysis.

### IBM SPSS Statistics

- **Original Use**: Social Sciences.
- **Current Uses**: Advanced analytics, text analytics, trend analysis, validation of assumptions, translating business problems into data science solutions.
- **Features**: Easy-to-use interface, minimal coding, efficient data management, accurate analysis.
- **Availability**: Closed source, requires a license.

### IBM Watson Studio

- **Integration**: Part of IBM Cloud Pak for Data.
- **Tools**: Jupyter notebooks, IBM closed source tools.
- **Features**: Web browser access, collaboration, exploratory analysis, machine learning and AI model building, SPSS Modeller flows.
- **Accessibility**: Public cloud, private cloud, desktop app.

### SAS Enterprise Miner

- **Functionality**: Graphical workbench for data mining, interactive data exploration.
- **Capabilities**: Managing information, mining and transforming data, statistical analysis.
- **Interface**: Graphical user interface for non-technical users.
- **Features**: Identifying patterns, exploring relationships and anomalies, big data analysis, validating findings.
- **Ease of Use**: Syntax simplicity, easy debugging, handling large databases, high security.

### Conclusion

- **Choosing Tools**: Based on data size, structures, features, visualization capabilities, infrastructure needs, ease of use, learnability.
- **Combination Use**: Common to use multiple tools to meet all data mining needs.

---

### Yaygın Veri Madenciliği Araçları

- **Elektronik Tablolar**:
    - Örnekler: Microsoft Excel, Google Sheets.
    - Kullanım Alanları: Temel veri madenciliği görevleri, dışa aktarılan verilerin barındırılması, kolay karşılaştırma, pivot tablolar.
    - Eklentiler: Excel için Veri Madenciliği İstemcisi, XLMiner, KnowledgeMiner, Metin Analizi, Metin Madenciliği, Google Analytics.

### R-Dili

- **Popülerlik**: İstatistiksel modelleme ve hesaplamalar için yaygın olarak kullanılır.
- **Kütüphaneler**: Regresyon, sınıflandırma, kümeleme, birliktelik kural madenciliği, metin madenciliği, aykırı değer tespiti, sosyal ağ analizi için yüzlerce kütüphane.
- **Paketler**:
    - tm: Metin madenciliği için bir çerçeve.
    - twitteR: Tweet madenciliği için bir çerçeve.
- **IDE**: R için açık kaynaklı bir ortam olan R Studio.

### Python

- **Kütüphaneler**:
    - Pandas: Veri yapıları ve analizi, temel sayısal hesaplamalar, istatistiksel analiz, veri görselleştirme.
    - NumPy: Matematiksel hesaplama, veri hazırlama, veri madenciliği için yerleşik fonksiyonlar.
- **Araçlar**: Veri madenciliği ve istatistiksel analiz için Jupyter Notebooks.

### IBM SPSS Statistics

- **Orijinal Kullanım**: Sosyal Bilimler.
- **Güncel Kullanım Alanları**: Gelişmiş analiz, metin analizi, trend analizi, varsayımların doğrulanması, iş sorunlarını veri bilimi çözümlerine çevirme.
- **Özellikler**: Kullanımı kolay arayüz, minimum kodlama, verimli veri yönetimi, doğru analiz.
- **Erişilebilirlik**: Kapalı kaynak, lisans gerektirir.

### IBM Watson Studio

- **Entegrasyon**: IBM Cloud Pak for Data'nın bir parçası.
- **Araçlar**: Jupyter not defterleri, IBM kapalı kaynak araçları.
- **Özellikler**: Web tarayıcısı erişimi, iş birliği, keşif analizi, makine öğrenimi ve AI model oluşturma, SPSS Modeller akışları.
- **Erişilebilirlik**: Genel bulut, özel bulut, masaüstü uygulaması.

### SAS Enterprise Miner

- **Fonksiyonellik**: Veri madenciliği için grafik çalışma masası, interaktif veri keşfi.
- **Kapasiteler**: Bilgi yönetimi, veri madenciliği ve dönüştürme, istatistiksel analiz.
- **Arayüz**: Teknik olmayan kullanıcılar için grafik kullanıcı arayüzü.
- **Özellikler**: Desenlerin belirlenmesi, ilişkilerin ve anomalilerin keşfi, büyük veri analizi, bulguların doğrulanması.
- **Kullanım Kolaylığı**: Söz dizimi basitliği, kolay hata ayıklama, büyük veritabanlarını yönetme, yüksek güvenlik.

### Sonuç

- **Araç Seçimi**: Veri boyutu, yapılar, özellikler, görselleştirme yetenekleri, altyapı ihtiyaçları, kullanım kolaylığı, öğrenilebilirlik baz alınarak yapılır.
- **Kombinasyon Kullanımı**: Tüm veri madenciliği ihtiyaçlarını karşılamak için birden fazla araç kullanmak yaygındır.

# Overview of Communicating and Sharing Data Analysis

### Understanding the Problem

- **Beginning**: Understanding the problem to be solved and the desired outcome.
- **Ending**: Communicating findings to impact decision-making.
- **Collaboration**: Involves multi-disciplinary skills across business functions.
- **Communication**: Success depends on clear, trustworthy insights.

### Audience Connection

- **Questions**:
    - Who is my audience?
    - What is important to them?
    - What will help them trust me?
- **Diverse Audience**: Varies in business functions, roles, impact by the problem.
- **Information Level**: Tailor presentation to audience's knowledge level.
- **Important Information**: Focus on what's most relevant to the audience.

### Presentation Structure

- **Not a Data Dump**: Avoid overwhelming with too much data.
- **Compelling Story**: Facts and figures alone don’t move people to action.
- **Business Problem Understanding**: Demonstrate your understanding to win attention and trust.
- **Language**: Use the organization’s business domain language.

### Data Credibility

- **Black Box**: Data is unfamiliar to the audience.
- **Credibility**: Establish by sharing data sources, hypotheses, and validations.
- **Key Assumptions**: Don’t gloss over them during analysis.

### Organizing Information

- **Logical Categories**: Qualitative vs. quantitative information.
- **Narrative Approach**: Top-down or bottom-up, be consistent.
- **Communication Formats**: Choose based on audience needs (executive summary, fact sheet, report).

### Inspiring Action

- **Grasp Significance**: Ensure audience understands the importance of insights.
- **Visualization**: A powerful tool for creating clear mental images.
- **Data Visualization**: Use graphs, charts, diagrams to show patterns and conclusions.
- **Trust and Understanding**: Help audience relate to findings and insights.

# Viewpoints: Storytelling in Data Analytics

## What role does storytelling play in Data Analysis?

- Storytelling with data is a critical skills for Data Analysts
- It’s important to tell a clear, concise, and compelling story to convince people to take action
- Develop a story for your data set to understand your data better
- Find the balance between telling a simple story and conveying the complexities of the data

---

- It doesn’t matter what information you have if you can’t communicate if effectively to your audience
- The best way to communicate your information is through visuals and telling a story

---

- Storytelling is an essential skill set - the last mile in delivery
- The ability to extract value from data and to tell a compelling story with data is critical

---

- Storytelling is crucial to data analytics
- Stories is how you convey your message
- A compelling story helps your audience resonate with your findings
- People remember stories
- Stories help build an emotional connect and drive people to action

# Introduction to Data Visualizations

### Purpose of Data Visualization

- **Goal**: Communicate information through visual elements like graphs, charts, and maps.
- **Objective**: Make information easy to comprehend, interpret, and retain.

### Choosing the Right Visualization

- **Key Questions**:
    - **Relationship**: What relationship am I trying to establish? (e.g., proportion of different product lines in total revenue)
    - **Comparison**: Do I need to compare multiple values or track changes over time? (e.g., products sold over three years)
    - **Correlation**: Do I need to show the correlation between two variables? (e.g., weather conditions and bookings)
    - **Anomalies**: Do I need to detect anomalies in data? (e.g., values that could skew findings)

### Static vs. Interactive Visualizations

- **Static**: Fixed representation of data.
- **Interactive**: Allows real-time changes and effects on related variables.

### Types of Graphs

- **Bar Charts**: Compare related data sets or parts of a whole. (e.g., population numbers of different countries)
- **Column Charts**: Compare values side-by-side, effective for showing change over time. (e.g., page views over months)
- **Pie Charts**: Show the breakdown of an entity into sub-parts and their proportions. (e.g., marketing leads by channel)
- **Line Charts**: Display trends and changes over time with continuous variables. (e.g., product sales over time)

### Dashboards

- **Purpose**: Organize and display reports and visualizations from multiple data sources in a single interface.
- **Usage**:
    - Monitor daily progress or overall health of a business function.
    - Present operational and analytical data.
    - Example: Marketing dashboard showing campaign reach, queries, and sales conversions, and comparing current and past conversion rates.
- **Benefits**:
    - Easy comprehension for average users.
    - Facilitates team collaboration.
    - Allows on-the-go report generation and evaluation from multiple perspectives.

### Summary

- **Value of Visualization**: Provides a clear summary of data relationships, trends, and patterns, making complex data more understandable and actionable.
- **Dashboard Utility**: Offers a comprehensive view and detailed analysis through a single interface, enhancing decision-making efficiency.

# Introduction to Visualization and Dash-boarding Software

### 1. **Spreadsheets**

- **Examples**: Microsoft Excel, Google Sheets
- **Features**:
    - Easy to learn with extensive documentation and tutorials.
    - **Excel**: Offers a wide range of chart types (e.g., bar, line, pie, scatter, Gantt, Waterfall). Provides chart recommendations and customization options.
    - **Google Sheets**: Similar chart types to Excel, with strong collaboration features. Automatic updates as data changes.

### 2. **Jupyter Notebook**

- **Description**: Open-source web application for data exploration and visualization.
- **Features**:
    - Supports Python libraries for visualization.
    - **Libraries**:
        - **Matplotlib**: Creates high-quality 2D and 3D plots. Widely used with strong community support.
        - **Bokeh**: Known for interactive, high-performance visualizations suitable for large data sets. Offers flexible styling and interactivity.
        - **Dash**: Python framework for interactive web-based visualizations. Does not require HTML or JavaScript knowledge, but supports cross-platform and mobile-ready applications.

### 3. **R-Studio and Shiny**

- **R-Studio**:
    - **Capabilities**: Basic (histograms, bar charts) and advanced (heat maps, 3D graphs) visualizations.
- **Shiny**:
    - **Description**: R package for building interactive web apps.
    - **Features**: Allows hosting of R objects and dashboards online. Popular for its ease of use among data professionals.

### 4. **IBM Cognos Analytics**

- **Description**: End-to-end analytics solution.
- **Features**:
    - Custom visualizations, time series forecasting, conditional formatting, and geospatial capabilities.
    - Offers recommendations for visualizations based on data.

### 5. **Tableau**

- **Description**: Interactive data visualization software.
- **Features**:
    - Drag-and-drop interface for creating dashboards and worksheets.
    - Supports importing R and Python scripts.
    - Compatible with various data sources including Excel, text files, relational databases, and cloud sources.

### 6. **Microsoft Power BI**

- **Description**: Cloud-based business and analytics service.
- **Features**:
    - Drag-and-drop interface for creating reports and dashboards.
    - Supports multiple data sources (Excel, SQL server, cloud repositories).
    - Interactive dashboards with tiles that update based on changes.

### Key Considerations

- **Ease of Use**: Choose tools that match your comfort level and the complexity of the visualization required.
- **Purpose**: Align tool selection with the goals of your visualization—whether it's basic charting, interactive dashboards, or advanced analytics.

### Summary

Each tool has unique strengths, ranging from simple spreadsheet options to advanced, interactive web-based solutions. When selecting a tool, consider ease of use, specific features, and the intended purpose of your visualization.

# Viewpoints: Visualization Tools

## What are the visualization tools you rely on the most and why?

- IBM Cognos Analytics
    - Import a spreadsheet, connect to a database, and visualize data
    - Perform complex analysis, such as, building and scheduling reports for automatic delivery
    - Search and combine multiple data sources
    - Create dashboards and filter and sort data dynamically

---

- Looker and Tableau
    - Easy to use by everyone for basic aggregation and sorting
    - R, for exploratory data analysis
    - Tidyverse, a collection of R packages for loading, aggregation and visualizing data

---

- Tableau and Power BI
    - Easy to pick up
    - Helpful for demonstrating data
    - Come with a host of built-in templates and libraries

---

- Microsoft Excel
    - Use macros to make sure data is clean and prepped for analysis